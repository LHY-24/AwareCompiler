#!/usr/bin/env python3
"""
æŸ¥çœ‹çŸ¥è¯†å›¾è°±ç»“æ„å’Œå†…å®¹
"""
import json
from build_kg import gen_kg_from_md
import os

def analyze_kg():
    """åˆ†æçŸ¥è¯†å›¾è°±ç»“æ„"""
    print("ğŸ” Analyzing knowledge graph generated from markdown...")
    md_file = "/root/AwareCompiler/knowledge_base/docs/autophase_features.md"
    if not os.path.exists(md_file):
        print(f"Error: {md_file} not found")
        return
    print(f"ğŸ“„ Source file: {md_file}")
    
    # è§£æçŸ¥è¯†å›¾è°±æ•°æ®
    kg_path = "/root/AwareCompiler/knowledge_base/compiler_kg/autophase_features_kg.json"
    if os.path.exists(kg_path):
        print(f"ğŸ“š Loading knowledge graph from {kg_path} ...")
        with open(kg_path, 'r') as f:
            kg_data = json.load(f)
    else:
        print("ğŸ“š Generating knowledge graph from markdown...")
        kg_data = gen_kg_from_md(md_file)           # TODOï¼šä½¿ç”¨lightragç”ŸæˆKG
        kg_dir = "/root/AwareCompiler/knowledge_base/compiler_kg"
        os.makedirs(kg_dir, exist_ok=True)
        with open(kg_path, 'w') as f:
            json.dump(kg_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š Knowledge Graph Statistics:")
    print(f"- Total Entities: {len(kg_data['entities'])}")
    print(f"- Total Relationships: {len(kg_data['relationships'])}")
    
    # åˆ†æå®ä½“ç±»å‹
    print(f"\nğŸ·ï¸ Entity Types Distribution:")
    entity_types = {}
    for entity in kg_data['entities']:
        etype = entity['entity_type']
        entity_types[etype] = entity_types.get(etype, 0) + 1
    for etype, count in sorted(entity_types.items()):
        print(f"  - {etype}: {count}")
    
    # å±•ç¤ºä¸€äº›ç‰¹å¾ç»„åˆå®ä½“ï¼ˆè¿™æ˜¯æˆ‘ä»¬çš„æ ¸å¿ƒå®ä½“ï¼‰
    print(f"\nğŸ¯ Feature Combination Examples (Core Entities):")
    feature_entities = [e for e in kg_data['entities'] if e['entity_type'] == 'autophase_feature_combination']
    for i, entity in enumerate(feature_entities[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
        print(f"\n  {i+1}. {entity['entity_name']}")
        description = entity['description']
        if "Recommended passes:" in description:
            passes_part = description.split("Recommended passes:")[1].split("Performance improvement:")[0].strip()
            perf_part = description.split("Performance improvement:")[1].strip()
            print(f"     ğŸ“ Description: {description.split('.')[0]}...")
            print(f"     ğŸ”§ Recommended passes: {passes_part}")
            print(f"     ğŸ“ˆ Performance: {perf_part}")
    
    # å±•ç¤ºä¼˜åŒ– pass å®ä½“
    print(f"\nğŸ› ï¸ Compiler Optimization Pass Examples:")
    pass_entities = [e for e in kg_data['entities'] if e['entity_type'] == 'compiler_optimization_pass']
    for i, entity in enumerate(pass_entities[:8]):  # æ˜¾ç¤ºå‰8ä¸ª
        print(f"  {i+1}. {entity['entity_name']}: {entity['description']}")
    
    # å±•ç¤ºæ€§èƒ½æ”¹è¿›çº§åˆ«
    print(f"\nğŸš€ Performance Improvement Levels:")
    perf_entities = [e for e in kg_data['entities'] if e['entity_type'] == 'performance_improvement_level']
    for entity in perf_entities:
        print(f"  - {entity['entity_name']}: {entity['description']}")
    
    # åˆ†æå…³ç³»ç±»å‹
    print(f"\nğŸ”— Relationship Examples:")
    relationships = kg_data['relationships']
    rel_types = {}
    for rel in relationships:
        rel_desc = rel['description']
        if "recommends optimization pass" in rel_desc:
            rel_types['feature_to_pass'] = rel_types.get('feature_to_pass', 0) + 1
        elif "achieves" in rel_desc and "performance improvement" in rel_desc:
            rel_types['feature_to_performance'] = rel_types.get('feature_to_performance', 0) + 1
        else:
            rel_types['other'] = rel_types.get('other', 0) + 1
    
    print(f"  Relationship types:")
    for rtype, count in rel_types.items():
        print(f"    - {rtype}: {count}")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å…³ç³»
    print(f"\n  Sample relationships:")
    feature_to_pass_rels = [r for r in relationships if "recommends optimization pass" in r['description']]
    for i, rel in enumerate(feature_to_pass_rels[:5]):
        print(f"    {i+1}. {rel['src_id']} -> {rel['tgt_id']}")
        print(f"       {rel['description']} (weight: {rel['weight']:.3f})")
    
    # å°†åˆ†æç»“æœä¿å­˜åˆ° JSON æ–‡ä»¶
    # output_file = "kg_analysis_result.json"
    # with open(output_file, 'w', encoding='utf-8') as f:
    #     json.dump(kg_data, f, indent=2, ensure_ascii=False)
    # print(f"\nğŸ’¾ Full knowledge graph data saved to: {output_file}")
    
    # æ€»ç»“
    print(f"\nâœ… Knowledge Graph Summary:")
    print(f"   ğŸ¯ Core concept: Autophase Features â†’ Optimization Passes")
    print(f"   ğŸ“Š Features: {len(feature_entities)} distinct feature combinations")
    print(f"   ğŸ› ï¸ Passes: {len(pass_entities)} optimization techniques")
    print(f"   ğŸš€ Performance: {len(perf_entities)} improvement levels")
    print(f"   ğŸ”— Mappings: {len(relationships)} feature-to-optimization relationships")
    
    print(f"\nğŸ‰ This knowledge graph enables agents to:")
    print(f"   1. Input program's Autophase features")
    print(f"   2. Find matching feature combinations")
    print(f"   3. Get recommended optimization passes")
    print(f"   4. Understand expected performance improvements")


if __name__ == "__main__":
    analyze_kg()
